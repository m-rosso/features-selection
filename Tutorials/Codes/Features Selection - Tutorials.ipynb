{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection\n",
    "## Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project has the objective of exploring and testing alternative methods of features selection. It has started with notebook \"Features Selection - Discussion\", where the relevance, approaches and methods of features selection are presented, mainly based on the reading of articles from specialized websites, besides of some books on machine learning fundamentals. As discussed on the first notebook of the series, the two main objectives of selecting features are reducing model complexity (thus saving memory and time) and eventually improving model performance.\n",
    "<br>\n",
    "<br>\n",
    "Notebook \"Features Selection - Discussion\" organizes popular methods based on three different classes of methods: *analytical methods*, which focus on the relationship between two variables (different inputs or an input and the output) or even consider only one variable at a time; *supervised learning selection*, which makes use of statistical learning methods that rank input variables according to their importance while training a model; and *exaustive methods*, which explore several distinct subsets of the entire set of available features.\n",
    "<br>\n",
    "<br>\n",
    "In order to explore and test alternative methods of features selection, the development of this project has led to four major contents: first, the already mentioned notebook \"Features Selection - Discussion\"; second, a Python class providing a unified API for implementing multiple methods from those three classes mentioned above (module \"features_selection\" and notebook \"Features Selection\"; third, a notebook which illustrates how to use the most relevant methods of features selection, by using either the native classes and functions or the developed class with a unifed API; and finally, a notebook (\"Features Selection - Empirical Tests\") implements tests for assessing the most adequate method for a given regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, a dataset of a regression problem from [UCI repository](https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized) is used for illustrating how to implement some of the most relevant features selection methods:\n",
    "1. Analytical methods:\n",
    "    * [*VarScreeningNumerical*](#variance)<a href='#variance'></a> class from my [Github](https://github.com/m-rosso/unsupervised-features-screening): the usage of this class supports either variance thresholding or the selection of features with the *K* highest variances, even though only variance thresholding is used here. Parameters:\n",
    "        * *threshold*: variance below which a feature is dropped out from the entire collection of features.\n",
    "    <br>\n",
    "    <br>\n",
    "    * [*CorrScreeningNumerical*](#correlation)<a href='#correlation'></a> class from my [Github](https://github.com/m-rosso/unsupervised-features-screening): it sorts features based on their variance and then sequentially drops those features with excessive pair-wise (linear) correlation. Parameters:\n",
    "        * *threshold*: correlation above which a feature is dropped out from the entire collection of features.\n",
    "<br>\n",
    "<br>\n",
    "2. Exaustive methods:\n",
    "    * [Recursive features elimination](#rfe)<a href='#rfe'></a> class from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html): given an initialized estimator, at each step a predefined number of the least relevant features are dropped until a given number is reached. Parameters:\n",
    "        * *estimator*: machine learning algorithm for training a model.\n",
    "        * *n_features_to_select*: final number of features to be selected.\n",
    "        * *step*: number of features to be dropped at each iteration.\n",
    "    <br>\n",
    "    <br>\n",
    "    * [RFECV](#rfecv)<a href='#rfecv'></a> class from[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html): selected features are defined according to the optimization of some performance metric that is calculated using K-folds cross-validation. Consequently, at each step the least important features are dropped, and from the final collection of models where each has a different number of features the best model is chosen through cross-validation. Parameters:\n",
    "        * *estimator*: machine learning algorithm for training a model.\n",
    "        * *min_features_to_select*: minimum final number of features to be selected.\n",
    "        * *step*: number of features to be dropped at each iteration.\n",
    "        * *cv*: configuration of K-folds cross-validation for final model selection.\n",
    "        * *scoring*: performance metric for final model selection.\n",
    "    <br>\n",
    "    <br>\n",
    "    * [SequentialFeatureSelector](#sfs)<a href='#sfs'></a> class from[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html): depending on the \"direction\" initialization parameter, a version of forward-stepwise selection or a version of backward-stepwise selection can be implemented. As with RFE, the number of features to be selected is another parameter that should ultimately be defined in order to optimize model performance. Parameters:\n",
    "        * *estimator*: machine learning algorithm for training a model.\n",
    "        * *n_features_to_select*: final number of features to be selected.\n",
    "        * *cv*: configuration of K-folds cross-validation for final model selection.\n",
    "        * *scoring*: performance metric for final model selection.\n",
    "        * *direction*: indicates whether forward or backward-stepwise selection should be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section [features selection](#features_selection)<a href='#features_selection'></a> not only has codes illustrating the use of the methods presented above, but also demonstrates how to [use](#fs_class)<a href='#fs_class'></a> the developed class that unifies all the major methods for selecting features. First, instead of initializing an object from *FeaturesSelection* class, three different static methods are used as functions for constructing a list with names of the selected features:\n",
    "1. *analytical_selection*: implements variance or correlation thresholding. Arguments:\n",
    "    * *method*: defines whether variance or correlation thresholding should take place.\n",
    "    * *threshold*: reference value for variance or correlation thresholding.\n",
    "<br>\n",
    "<br>\n",
    "2. *supervised_selection*: executes supervised learning selection, under which only those features whose importance is greater than some threshold are selected, where this importance is calculated as a model is trained. Arguments:\n",
    "    * *estimator*: machine learning algorithm containing either a \"coef_\" or a \"feature_importances_\" attribute.\n",
    "    * *threshold*: importance value above which features are selected.\n",
    "<br>\n",
    "<br>\n",
    "3. *exaustive_selection*: implements one of the following exaustive methods (presented above): RFE (method='rfe'), RFECV (method='rfecv'), SequentialFeatureSelector (method='sequential'), random selection (method='random_selection'). Random selection, not previously mentioned, defines a collection of models with different numbers of features (all randomly picked), and then chooses the best model using K-folds CV.\n",
    "    * Arguments for running RFE:\n",
    "        * estimator: machine learning algorithm.\n",
    "        * num_folds: number of folds of K-folds CV for selecting final model.\n",
    "        * metric: performance metric for selecting final model.\n",
    "        * max_num_feats: maximum number of features to be tested.\n",
    "        * step: number of features to be dropped at each iteration.\n",
    "    <br>\n",
    "    <br>\n",
    "    * Arguments for running RFECV:\n",
    "        * estimator: machine learning algorithm.\n",
    "        * num_folds: number of folds of K-folds CV for selecting final model.\n",
    "        * metric: performance metric for selecting final model.\n",
    "        * min_num_feats: minimum number of features to be selected.\n",
    "        * step: number of features to be dropped at each iteration.\n",
    "    <br>\n",
    "    <br>\n",
    "    * Arguments for running SequentialFeatureSelector:\n",
    "        * estimator: machine learning algorithm.\n",
    "        * num_folds: number of folds of K-folds CV for selecting final model.\n",
    "        * metric: performance metric for selecting final model.\n",
    "        * max_num_feats: maximum number of features to be tested.\n",
    "        * direction: indicates whether forward or backward-stepwise selection should be implemented.\n",
    "    <br>\n",
    "    <br>\n",
    "    * Arguments for running random selection:\n",
    "        * estimator: machine learning algorithm.\n",
    "        * num_folds: number of folds of K-folds CV for selecting final model.\n",
    "        * metric: performance metric for selecting final model.\n",
    "        * max_num_feats: maximum number of features to be tested.\n",
    "        * step: number of features to be randomly included at each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main difference between using static methods or initializing an [object of *FeaturesSelection* class](#init_fs)<a href='#init_fs'></a> is that the static methods require the definition of two additional arguments: \"inputs\" and \"output\", dataframes with training data. When using directly the *FeaturesSelection* class, after passing all arguments for initialization, the \"select_features\" method should be called having \"inputs\" and \"output\" as arguments. Another difference relies on the fact that \"estimator\" parameter should be declared in the \"select_features\" method whenever supervised learning selection or exaustive methods are to be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Functions and classes](#functions_classes)<a href='#functions_classes'></a>.\n",
    "3. [Settings](#settings)<a href='#settings'></a>.\n",
    "4. [Importing datasets](#imports)<a href='#imports'></a>.\n",
    "    * [Features and outcome variables](#feats_outcomes)<a href='#feats_outcomes'></a>.\n",
    "<br>\n",
    "<br>\n",
    "5. [Features selection](#features_selection)<a href='#features_selection'></a>.\n",
    "    * [Analytical methods](#analytical_methods)<a href='#analytical_methods'></a>.\n",
    "    * [Exaustive methods](#exaustive_methods)<a href='#exaustive_methods'></a>.\n",
    "    * [Class for features selection](#fs_class)<a href='#fs_class'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV, SequentialFeatureSelector\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions_classes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_test_split\n",
    "from pre_process import pre_process\n",
    "from screening_features import VarScreeningNumerical, CorrScreeningNumerical\n",
    "from features_selection import FeaturesSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='settings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare whether to export results:\n",
    "export = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define whether to apply logarithmic transformation over numerical variables:\n",
    "log_transform = True\n",
    "\n",
    "# Define whether to standardize numerical variables:\n",
    "standardize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines whether to implement analytical methods:\n",
    "analytical_selection = True\n",
    "variance_screening = True # Selection based on the variance of features.\n",
    "correlation_screening = True # Selection based on the correlation among features.\n",
    "\n",
    "# Defines whether to implement supervised features selection:\n",
    "supervised_selection = False\n",
    "\n",
    "# Defines whether to implement exaustive methods:\n",
    "exaustive_selection = True\n",
    "rfe_selection = True # Recursive feature elimination.\n",
    "rfecv_selection = True # Recursive feature elimination with cross-validation.\n",
    "sfs_selection = True # Sequential feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feats_outcomes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and outcome variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (2215, 130).\n",
      "Number of distinct instances: 2215.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1845.9</td>\n",
       "      <td>9.63</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>41.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2186.7</td>\n",
       "      <td>3.84</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>127.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2780.9</td>\n",
       "      <td>4.37</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>218.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  ...  LandArea  \\\n",
       "0           3.10          1.37         91.78          6.50  ...       6.5   \n",
       "1           2.82          0.80         95.57          3.44  ...      10.6   \n",
       "2           2.43          0.74         94.33          3.43  ...      10.6   \n",
       "\n",
       "   PopDens  PctUsePubTrans  PolicCars  PolicOperBudg  LemasPctPolicOnPatr  \\\n",
       "0   1845.9            9.63          ?              ?                    ?   \n",
       "1   2186.7            3.84          ?              ?                    ?   \n",
       "2   2780.9            4.37          ?              ?                    ?   \n",
       "\n",
       "   LemasGangUnitDeploy  LemasPctOfficDrugUn  PolicBudgPerPop  \\\n",
       "0                    ?                  0.0                ?   \n",
       "1                    ?                  0.0                ?   \n",
       "2                    ?                  0.0                ?   \n",
       "\n",
       "   ViolentCrimesPerPop  \n",
       "0                41.02  \n",
       "1               127.56  \n",
       "2               218.59  \n",
       "\n",
       "[3 rows x 130 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data:\n",
    "df = pd.read_csv('../Datasets/CommViolPredUnnormalizedData.txt', header=None)\n",
    "\n",
    "# Columns names:\n",
    "columns_names = pd.read_csv('../Datasets/columns_names.csv')\n",
    "\n",
    "# Defining columns names:\n",
    "df.columns = list(columns_names['column_name'])\n",
    "\n",
    "# Auxiliary variables:\n",
    "drop_vars = ['communityname', 'countyCode', 'communityCode', 'fold', 'ViolentCrimesPerPop']\n",
    "\n",
    "# Additional outcome variables:\n",
    "additional_outcomes = ['nonViolPerPop', 'murders', 'murdPerPop', 'rapes', 'rapesPerPop', 'robberies',\n",
    "                       'robbbPerPop', 'assaults', 'assaultPerPop', 'burglaries', 'burglPerPop', 'larcenies',\n",
    "                       'larcPerPop', 'autoTheft', 'autoTheftPerPop', 'arsons', 'arsonsPerPop']\n",
    "df.drop(additional_outcomes, axis=1, inplace=True)\n",
    "\n",
    "print(f'Shape of data: {df.shape}.')\n",
    "print(f'Number of distinct instances: {len(np.unique(df[\"communityname\"] + df[\"state\"]))}.')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting missing values and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over columns:\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].apply(lambda x: np.NaN if x == '?' else x)\n",
    "    \n",
    "    # Converting data into float:\n",
    "    if c not in ['communityname', 'state', 'countyCode', 'communityCode', 'fold']:\n",
    "        df[c] = df[c].apply(float)\n",
    "    \n",
    "    # Treating missings for support variables:\n",
    "    if c in ['communityname', 'countyCode', 'communityCode', 'fold']:\n",
    "        df[c] = ['' if pd.isnull(x) else x for x in df[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (1994, 130).\n",
      "Number of distinct instances: 1994.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1845.9</td>\n",
       "      <td>9.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2186.7</td>\n",
       "      <td>3.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>29344.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2780.9</td>\n",
       "      <td>4.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1     11980.0   \n",
       "1           Marpletownship    PA         45         47616     1     23123.0   \n",
       "2               Tigardcity    OR                              1     29344.0   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  ...  LandArea  \\\n",
       "0           3.10          1.37         91.78          6.50  ...       6.5   \n",
       "1           2.82          0.80         95.57          3.44  ...      10.6   \n",
       "2           2.43          0.74         94.33          3.43  ...      10.6   \n",
       "\n",
       "   PopDens  PctUsePubTrans  PolicCars  PolicOperBudg  LemasPctPolicOnPatr  \\\n",
       "0   1845.9            9.63        NaN            NaN                  NaN   \n",
       "1   2186.7            3.84        NaN            NaN                  NaN   \n",
       "2   2780.9            4.37        NaN            NaN                  NaN   \n",
       "\n",
       "   LemasGangUnitDeploy  LemasPctOfficDrugUn  PolicBudgPerPop  \\\n",
       "0                  NaN                  0.0              NaN   \n",
       "1                  NaN                  0.0              NaN   \n",
       "2                  NaN                  0.0              NaN   \n",
       "\n",
       "   ViolentCrimesPerPop  \n",
       "0                41.02  \n",
       "1               127.56  \n",
       "2               218.59  \n",
       "\n",
       "[3 rows x 130 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping instances with missing for the outcome variable:\n",
    "df = df[df['ViolentCrimesPerPop'].isnull()==False]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Shape of data: {df.shape}.')\n",
    "print(f'Number of distinct instances: {len(np.unique(df[\"communityname\"] + df[\"state\"]))}.')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_ratio=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mCLASSIFYING FEATURES AND EARLY SELECTION\u001b[0m\n",
      "\n",
      "\n",
      "Initial number of features: 125.\n",
      "0 features were dropped for excessive number of missings!\n",
      "0 features were dropped for having no variance!\n",
      "125 remaining features.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mASSESSING MISSING VALUES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of features with missings:\u001b[0m 23 out of 130 features (17.69%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 213 out of 1496 observations (14.24%).\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of features with missings:\u001b[0m 22 out of 130 features (16.92%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 70 out of 498 observations (14.06%).\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 124.\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 124.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mStandard scaling training data...\u001b[0m\n",
      "\u001b[1mStandard scaling test data...\u001b[0m\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mTREATING MISSING VALUES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTreating missing values of training data...\u001b[0m\n",
      "\u001b[1mTreating missing values of test data...\u001b[0m\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mTRANSFORMING CATEGORICAL FEATURES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mNumber of categorical features:\u001b[0m 1\n",
      "\u001b[1mNumber of overall selected dummies:\u001b[0m 28.\n",
      "\u001b[1mShape of df_train_scaled:\u001b[0m (1496, 180).\n",
      "\u001b[1mShape of df_test_scaled:\u001b[0m (498, 179).\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mFINAL ASSESSMENT OF MISSINGS AND CHECKING DATASETS CONSISTENCY\u001b[0m\n",
      "\n",
      "\n",
      "Training and test data are consistent with each other.\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, df_train_scaled, df_test_scaled = pre_process(training_data=df_train, test_data=df_test,\n",
    "                                                                 vars_to_drop=drop_vars,\n",
    "                                                                 log_transform=True, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features_selection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete collection of features:\n",
    "all_vars = list(df_train_scaled.drop(drop_vars, axis=1).columns)\n",
    "\n",
    "# Numerical features:\n",
    "cont_vars = [c for c in df_train.columns if 'L#' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analytical_methods'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analytical_selection:\n",
    "    # Numerical features:\n",
    "    cont_df = df_train[cont_vars].copy()\n",
    "    means = dict(zip(cont_df.mean().index, cont_df.mean().values))\n",
    "\n",
    "    # Loop over numerical features:\n",
    "    for f in means:\n",
    "        # Scaling each variable:\n",
    "        cont_df[f] = [x/means[f] for x in cont_df[f]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection based on variance<a id='variance'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [here](https://github.com/m-rosso/unsupervised-features-screening) for the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 124 features, 40 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for variance thresholding:\n",
    "var_screen = VarScreeningNumerical(features=cont_vars,\n",
    "                                   select_k=False, thresholding=True, variance_threshold=0.1)\n",
    "\n",
    "# Selecting features based on their variances:\n",
    "var_screen.select_feat(data=cont_df)\n",
    "var_screen_features = var_screen.selected_feat\n",
    "\n",
    "print(f'From {len(cont_vars)} features, {len(var_screen_features)} were selected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection based on correlation<a id='correlation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [here](https://github.com/m-rosso/unsupervised-features-screening) for the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 124 features, 84 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for correlation thresholding:\n",
    "corr_screen = CorrScreeningNumerical(features=cont_vars,\n",
    "                                     corr_threshold=0.8)\n",
    "\n",
    "# Selecting features based on the correlation among them:\n",
    "corr_screen.select_feat(data=cont_df)\n",
    "corr_screen_features = corr_screen.selected_feat\n",
    "\n",
    "print(f'From {len(cont_vars)} features, {len(corr_screen_features)} were selected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exaustive_methods'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exaustive methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE<a id='rfe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 1 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for the recursive feature elimination:\n",
    "rfe_select = RFE(estimator=Lasso(alpha=1.0),\n",
    "                 n_features_to_select=1,\n",
    "                 step=1)\n",
    "\n",
    "# Running the recursive feature elimination:\n",
    "rfe_selec = rfe_select.fit(X=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                           y=df_train_scaled['ViolentCrimesPerPop'])\n",
    "\n",
    "# Selected features:\n",
    "rfe_features = [c for s, c in zip(rfe_select.support_, all_vars) if s]\n",
    "print(f'From {len(all_vars)} features, {len(rfe_features)} were selected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV<a id='rfecv'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 108 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for the recursive feature elimination with cross-validation:\n",
    "rfecv_select = RFECV(estimator=Lasso(alpha=1.0),\n",
    "                     step=1,\n",
    "                     min_features_to_select=1,\n",
    "                     cv=5,\n",
    "                     scoring='r2')\n",
    "\n",
    "# Running the recursive feature elimination with cross-validation:\n",
    "rfecv_select = rfecv_select.fit(X=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                                y=df_train_scaled['ViolentCrimesPerPop'])\n",
    "\n",
    "# Selected features:\n",
    "rfecv_features = [c for s, c in zip(rfecv_select.support_, all_vars) if s]\n",
    "print(f'From {len(all_vars)} features, {len(rfecv_features)} were selected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SequentialFeatureSelector<a id='sfs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 1 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for the sequential feature selection:\n",
    "sfs_select = SequentialFeatureSelector(estimator=Lasso(alpha=1.0),\n",
    "                                       n_features_to_select=1,\n",
    "                                       direction='forward',\n",
    "                                       scoring='r2',\n",
    "                                       cv=5)\n",
    "\n",
    "# Running the sequential feature selection:\n",
    "sfs_select = sfs_select.fit(X=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                            y=df_train_scaled['ViolentCrimesPerPop'])\n",
    "\n",
    "# Selected features:\n",
    "sfs_features = [c for s, c in zip(sfs_select.support_, all_vars) if s]\n",
    "print(f'From {len(all_vars)} features, {len(sfs_features)} were selected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fs_class'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the Python module containing the *FeaturesSelection* class for the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 124 features, 40 were selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.analytical_selection(inputs=cont_df, method='variance', threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 124 features, 84 were selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.analytical_selection(inputs=cont_df, method='correlation', threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised learning selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 97 were selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.supervised_selection(Lasso(alpha=1.0),\n",
    "                                                           inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                                                           output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                                                           threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exaustive methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 1 were selected!\n",
      "From 174 features, 2 were selected!\n",
      "From 174 features, 3 were selected!\n",
      "From 174 features, 4 were selected!\n",
      "From 174 features, 5 were selected!\n",
      "\n",
      "From 174 features, 5 were finally selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.exaustive_selection(estimator=Lasso(alpha=1.0),\n",
    "                                                          inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                                                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                                                          method='rfe', num_folds=5, metric='r2',\n",
    "                                                          max_num_feats=5, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 108 were selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.exaustive_selection(estimator=Lasso(alpha=1.0),\n",
    "                                                          inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                                                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                                                          method='rfecv', num_folds=5, metric='r2',\n",
    "                                                          min_num_feats=1, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 1 were selected!\n",
      "From 174 features, 2 were selected!\n",
      "From 174 features, 3 were selected!\n",
      "From 174 features, 4 were selected!\n",
      "From 174 features, 5 were selected!\n",
      "\n",
      "From 174 features, 5 were finally selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.exaustive_selection(estimator=Lasso(alpha=1.0),\n",
    "                                                          inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                                                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                                                          method='sequential', num_folds=5, metric='r2',\n",
    "                                                          max_num_feats=5, direction='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 10 were selected!\n",
      "From 174 features, 20 were selected!\n",
      "From 174 features, 30 were selected!\n",
      "From 174 features, 40 were selected!\n",
      "From 174 features, 50 were selected!\n",
      "From 174 features, 60 were selected!\n",
      "From 174 features, 70 were selected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus_rosso/fsvenv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59545.00501406193, tolerance: 49202.552026599704\n",
      "  positive)\n",
      "/home/matheus_rosso/fsvenv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78106.14563831687, tolerance: 47339.469963994554\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 80 were selected!\n",
      "From 174 features, 90 were selected!\n",
      "From 174 features, 100 were selected!\n",
      "\n",
      "From 174 features, 80 were finally selected!\n"
     ]
    }
   ],
   "source": [
    "selected_features = FeaturesSelection.exaustive_selection(estimator=Lasso(alpha=1.0),\n",
    "                                                          inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                                                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                                                          method='random_selection', num_folds=5, metric='r2',\n",
    "                                                          max_num_feats=100, step=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='init_fs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the *FeaturesSelection* class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 124 features, 40 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Variance selection:\n",
    "selection = FeaturesSelection(method='variance', threshold=0.1)\n",
    "\n",
    "selection.select_features(inputs=cont_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 124 features, 84 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Correlation selection:\n",
    "selection = FeaturesSelection(method='correlation', threshold=0.8)\n",
    "\n",
    "selection.select_features(inputs=cont_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 176 features, 99 were selected!\n"
     ]
    }
   ],
   "source": [
    "selection = FeaturesSelection(method='supervised', threshold=0)\n",
    "\n",
    "selection.select_features(inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                          estimator=Lasso(alpha=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exaustive methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 176 features, 1 were selected!\n",
      "From 176 features, 2 were selected!\n",
      "From 176 features, 3 were selected!\n",
      "From 176 features, 4 were selected!\n",
      "From 176 features, 5 were selected!\n",
      "\n",
      "From 176 features, 5 were finally selected!\n"
     ]
    }
   ],
   "source": [
    "# Recursive feature elimination:\n",
    "selection = FeaturesSelection(method='rfe', num_folds=5, metric='r2',\n",
    "                              max_num_feats=5, step=1)\n",
    "\n",
    "selection.select_features(inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                          estimator=Lasso(alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 108 were selected!\n"
     ]
    }
   ],
   "source": [
    "# Recursive feature elimination with cross-validation:\n",
    "selection = FeaturesSelection(method='rfecv', num_folds=5, metric='r2',\n",
    "                              min_num_feats=1, step=1)\n",
    "\n",
    "selection.select_features(inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                          estimator=Lasso(alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 1 were selected!\n",
      "From 174 features, 2 were selected!\n",
      "From 174 features, 3 were selected!\n",
      "From 174 features, 4 were selected!\n",
      "From 174 features, 5 were selected!\n",
      "\n",
      "From 174 features, 5 were finally selected!\n"
     ]
    }
   ],
   "source": [
    "# Sequential feature selection:\n",
    "selection = FeaturesSelection(method='sequential', num_folds=5, metric='r2',\n",
    "                              max_num_feats=5, step=1, direction='forward')\n",
    "\n",
    "selection.select_features(inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                          estimator=Lasso(alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 174 features, 10 were selected!\n",
      "From 174 features, 20 were selected!\n",
      "From 174 features, 30 were selected!\n",
      "From 174 features, 40 were selected!\n",
      "From 174 features, 50 were selected!\n",
      "From 174 features, 60 were selected!\n",
      "From 174 features, 70 were selected!\n",
      "From 174 features, 80 were selected!\n",
      "From 174 features, 90 were selected!\n",
      "From 174 features, 100 were selected!\n",
      "\n",
      "From 174 features, 70 were finally selected!\n"
     ]
    }
   ],
   "source": [
    "# Random selection:\n",
    "selection = FeaturesSelection(method='random_selection', num_folds=5, metric='r2',\n",
    "                              max_num_feats=100, step=10)\n",
    "\n",
    "selection.select_features(inputs=df_train_scaled.drop(drop_vars, axis=1),\n",
    "                          output=df_train_scaled['ViolentCrimesPerPop'],\n",
    "                          estimator=Lasso(alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsvenv",
   "language": "python",
   "name": "fsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
